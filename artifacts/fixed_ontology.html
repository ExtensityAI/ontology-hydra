<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 100vh;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             
             #loadingBar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width: 100%;
                 height: 100vh;
                 background-color:rgba(200,200,200,0.8);
                 -webkit-transition: all 0.5s ease;
                 -moz-transition: all 0.5s ease;
                 -ms-transition: all 0.5s ease;
                 -o-transition: all 0.5s ease;
                 transition: all 0.5s ease;
                 opacity:1;
             }

             #bar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width:20px;
                 height:20px;
                 margin:auto auto auto auto;
                 border-radius:11px;
                 border:2px solid rgba(30,30,30,0.05);
                 background: rgb(0, 173, 246); /* Old browsers */
                 box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
             }

             #border {
                 position:absolute;
                 top:10px;
                 left:10px;
                 width:500px;
                 height:23px;
                 margin:auto auto auto auto;
                 box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
                 border-radius:10px;
             }

             #text {
                 position:absolute;
                 top:8px;
                 left:530px;
                 width:30px;
                 height:50px;
                 margin:auto auto auto auto;
                 font-size:22px;
                 color: #000000;
             }

             div.outerBorder {
                 position:relative;
                 top:400px;
                 width:600px;
                 height:44px;
                 margin:auto auto auto auto;
                 border:8px solid rgba(0,0,0,0.1);
                 background: rgb(252,252,252); /* Old browsers */
                 background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
                 background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
                 background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
                 background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
                 background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
                 background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
                 filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
                 border-radius:72px;
                 box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
             }
             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
            <div id="loadingBar">
              <div class="outerBorder">
                <div id="text">0%</div>
                <div id="border">
                  <div id="bar"></div>
                </div>
              </div>
            </div>
        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#F1C40F", "font": {"color": "black"}, "id": "ApproximatorFunction", "label": "ApproximatorFunction", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Function", "label": "Function", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Reward", "label": "Reward", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "StateTransition", "label": "StateTransition", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "LearningProcess", "label": "LearningProcess", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Community", "label": "Community", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Group", "label": "Group", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "DelayedEpisodicReward", "label": "DelayedEpisodicReward", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "DelayedReward", "label": "DelayedReward", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "DiverseEnvironment", "label": "DiverseEnvironment", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ReinforcementLearning", "label": "ReinforcementLearning", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "NeuralNetworkModelSelection", "label": "NeuralNetworkModelSelection", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "SelectionStrategy", "label": "SelectionStrategy", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "CreditAssignment", "label": "CreditAssignment", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "StateInformationFlow", "label": "StateInformationFlow", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "RingMDP", "label": "RingMDP", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "MarkovDecisionProcess", "label": "MarkovDecisionProcess", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "RewardPredictionStrategy", "label": "RewardPredictionStrategy", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "UnderrepresentedGroup", "label": "UnderrepresentedGroup", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "PolicyGradientMethod", "label": "PolicyGradientMethod", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "LearningAlgorithm", "label": "LearningAlgorithm", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ClassifierBasedLearning", "label": "ClassifierBasedLearning", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "IndirectLearning", "label": "IndirectLearning", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ReturnEquivalentSDP", "label": "ReturnEquivalentSDP", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "StochasticDecisionProcess", "label": "StochasticDecisionProcess", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "GoalParameterization", "label": "GoalParameterization", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "LearningObjective", "label": "LearningObjective", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "GoalGeneration", "label": "GoalGeneration", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ConfidenceInterval", "label": "ConfidenceInterval", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "StatisticalMeasure", "label": "StatisticalMeasure", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "WassersteinDistance", "label": "WassersteinDistance", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "DistanceMetric", "label": "DistanceMetric", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "FeatureAbstraction", "label": "FeatureAbstraction", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "SandboxedExecutionEnvironment", "label": "SandboxedExecutionEnvironment", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ExecutionEnvironment", "label": "ExecutionEnvironment", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "BiasVarianceTradeOff", "label": "BiasVarianceTradeOff", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "OptimizationCriterion", "label": "OptimizationCriterion", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "InfluenceOnRewardVariance", "label": "InfluenceOnRewardVariance", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Demonstration", "label": "Demonstration", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "CorrelationDemonstration", "label": "CorrelationDemonstration", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "VEOrder", "label": "VEOrder", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "LearningOrder", "label": "LearningOrder", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ExampleBasedControl", "label": "ExampleBasedControl", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ControlIntegration", "label": "ControlIntegration", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "NonlinearFunctionApproximation", "label": "NonlinearFunctionApproximation", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "FunctionApproximation", "label": "FunctionApproximation", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "LongTermCreditAssignment", "label": "LongTermCreditAssignment", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "OptimalRewardRedistribution", "label": "OptimalRewardRedistribution", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "RewardRedistribution", "label": "RewardRedistribution", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "StaticRewardMitigation", "label": "StaticRewardMitigation", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "SpuriousRewardMitigationStrategy", "label": "SpuriousRewardMitigationStrategy", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "LatentStateRepresentation", "label": "LatentStateRepresentation", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Representation", "label": "Representation", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ResidualBiasCorrectionTechnique", "label": "ResidualBiasCorrectionTechnique", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "HierarchicalReinforcementLearning", "label": "HierarchicalReinforcementLearning", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "LSTMNetwork", "label": "LSTMNetwork", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "NetworkStructure", "label": "NetworkStructure", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "DownstreamReinforcementLearning", "label": "DownstreamReinforcementLearning", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "PolicyComparison", "label": "PolicyComparison", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Policy", "label": "Policy", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "RewardPredictiveAssociation", "label": "RewardPredictiveAssociation", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Association", "label": "Association", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ValuePolytope", "label": "ValuePolytope", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "GeometricProperty", "label": "GeometricProperty", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ActionRepeatConfiguration", "label": "ActionRepeatConfiguration", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "RecursiveClassificationApproach", "label": "RecursiveClassificationApproach", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ClassificationApproach", "label": "ClassificationApproach", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "GRUArchitecture", "label": "GRUArchitecture", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "NeuralNetwork", "label": "NeuralNetwork", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "PerformanceMetric", "label": "PerformanceMetric", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "UnsupervisedVisualRepresentation", "label": "UnsupervisedVisualRepresentation", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "VisualRepresentation", "label": "VisualRepresentation", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "TemporalResolution", "label": "TemporalResolution", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "AcademicWorkshop", "label": "AcademicWorkshop", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Workshop", "label": "Workshop", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "EnhancedPredictionProbingPerformance", "label": "EnhancedPredictionProbingPerformance", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "PredictionProbingPerformance", "label": "PredictionProbingPerformance", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "MultiTaskLearning", "label": "MultiTaskLearning", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "DivergenceBasedRegularization", "label": "DivergenceBasedRegularization", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "RegularizationTechnique", "label": "RegularizationTechnique", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ModelFidelity", "label": "ModelFidelity", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "QualityMetric", "label": "QualityMetric", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "QValue", "label": "QValue", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Estimation", "label": "Estimation", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "LearningStability", "label": "LearningStability", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "LearningDynamic", "label": "LearningDynamic", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "FeedforwardNetwork", "label": "FeedforwardNetwork", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "FiniteStateMachineMemory", "label": "FiniteStateMachineMemory", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Memory", "label": "Memory", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "StateTransitionDynamics", "label": "StateTransitionDynamics", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "RewardFunction", "label": "RewardFunction", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "DenseSurrogateRewardFunction", "label": "DenseSurrogateRewardFunction", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "RewardManagement", "label": "RewardManagement", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "TransitionFunction", "label": "TransitionFunction", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "AIResearch", "label": "AIResearch", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ResearchField", "label": "ResearchField", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "RewardSignal", "label": "RewardSignal", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "EnergyDistance", "label": "EnergyDistance", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "RecurrentNeuralNetwork", "label": "RecurrentNeuralNetwork", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "AdaptiveRewardMitigation", "label": "AdaptiveRewardMitigation", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "MemoryUtilizationStrategy", "label": "MemoryUtilizationStrategy", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "MemoryPreservationStrategy", "label": "MemoryPreservationStrategy", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ModelCapacity", "label": "ModelCapacity", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Capacity", "label": "Capacity", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "TemporalCreditAssignment", "label": "TemporalCreditAssignment", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "IterativeControlMethod", "label": "IterativeControlMethod", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ControlMethod", "label": "ControlMethod", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ExampleBasedLearning", "label": "ExampleBasedLearning", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "DirectLearning", "label": "DirectLearning", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "PlanningPerformanceDifference", "label": "PlanningPerformanceDifference", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "PerformanceComparison", "label": "PerformanceComparison", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ScalableReinforcementLearning", "label": "ScalableReinforcementLearning", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "EnergyOptimization", "label": "EnergyOptimization", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "DynamicGameEnvironment", "label": "DynamicGameEnvironment", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "GameEnvironment", "label": "GameEnvironment", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "SubManager", "label": "SubManager", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Manager", "label": "Manager", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "MemoryPerformance", "label": "MemoryPerformance", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "HierarchicalReinforcementLearningArchitecture", "label": "HierarchicalReinforcementLearningArchitecture", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "FalseRingMDP", "label": "FalseRingMDP", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "LongHorizonImitationLearning", "label": "LongHorizonImitationLearning", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ImitationLearning", "label": "ImitationLearning", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ActionExecution", "label": "ActionExecution", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "RecurrentNetwork", "label": "RecurrentNetwork", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "DelayedCreditAssignment", "label": "DelayedCreditAssignment", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "TemporalAttentionMechanism", "label": "TemporalAttentionMechanism", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "HistoryCompressionFunction", "label": "HistoryCompressionFunction", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "DomainAgnosticBenchmark", "label": "DomainAgnosticBenchmark", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "Benchmark", "label": "Benchmark", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ModernControlMethod", "label": "ModernControlMethod", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "AgentTemporalAttentionMechanism", "label": "AgentTemporalAttentionMechanism", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "DecentralizedAgentPolicy", "label": "DecentralizedAgentPolicy", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "TaskDelegation", "label": "TaskDelegation", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "OptimalPolicySelection", "label": "OptimalPolicySelection", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "PolicySelection", "label": "PolicySelection", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "EpisodicRewardDecomposition", "label": "EpisodicRewardDecomposition", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "TemporalAttentionPattern", "label": "TemporalAttentionPattern", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "FacilityUsage", "label": "FacilityUsage", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "ResourceAllocation", "label": "ResourceAllocation", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "DomainSpecificBenchmark", "label": "DomainSpecificBenchmark", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "HierarchicalLearningArchitecture", "label": "HierarchicalLearningArchitecture", "shape": "dot", "title": "CLASS"}, {"color": "#F1C40F", "font": {"color": "black"}, "id": "SelfSupervisedLearning", "label": "SelfSupervisedLearning", "shape": "dot", "title": "CLASS"}, {"color": "#9B59B6", "font": {"color": "black"}, "id": "datatype: xsd:float", "label": "xsd:float", "shape": "dot", "title": "Datatype"}, {"color": "#9B59B6", "font": {"color": "black"}, "id": "datatype: xsd:string", "label": "xsd:string", "shape": "dot", "title": "Datatype"}]);
                  edges = new vis.DataSet([{"arrows": "to", "color": "#34495E", "from": "ApproximatorFunction", "label": "subClassOf", "to": "Function"}, {"arrows": "to", "color": "#34495E", "from": "Reward", "label": "subClassOf", "to": "Function"}, {"arrows": "to", "color": "#34495E", "from": "StateTransition", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "Community", "label": "subClassOf", "to": "Group"}, {"arrows": "to", "color": "#34495E", "from": "DelayedEpisodicReward", "label": "subClassOf", "to": "DelayedReward"}, {"arrows": "to", "color": "#34495E", "from": "DiverseEnvironment", "label": "subClassOf", "to": "ReinforcementLearning"}, {"arrows": "to", "color": "#34495E", "from": "NeuralNetworkModelSelection", "label": "subClassOf", "to": "SelectionStrategy"}, {"arrows": "to", "color": "#34495E", "from": "CreditAssignment", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "StateInformationFlow", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "RingMDP", "label": "subClassOf", "to": "MarkovDecisionProcess"}, {"arrows": "to", "color": "#34495E", "from": "RewardPredictionStrategy", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "UnderrepresentedGroup", "label": "subClassOf", "to": "Community"}, {"arrows": "to", "color": "#34495E", "from": "PolicyGradientMethod", "label": "subClassOf", "to": "LearningAlgorithm"}, {"arrows": "to", "color": "#34495E", "from": "ClassifierBasedLearning", "label": "subClassOf", "to": "IndirectLearning"}, {"arrows": "to", "color": "#34495E", "from": "ReturnEquivalentSDP", "label": "subClassOf", "to": "StochasticDecisionProcess"}, {"arrows": "to", "color": "#34495E", "from": "GoalParameterization", "label": "subClassOf", "to": "LearningObjective"}, {"arrows": "to", "color": "#34495E", "from": "GoalGeneration", "label": "subClassOf", "to": "LearningObjective"}, {"arrows": "to", "color": "#34495E", "from": "DelayedReward", "label": "subClassOf", "to": "Reward"}, {"arrows": "to", "color": "#34495E", "from": "ConfidenceInterval", "label": "subClassOf", "to": "StatisticalMeasure"}, {"arrows": "to", "color": "#34495E", "from": "WassersteinDistance", "label": "subClassOf", "to": "DistanceMetric"}, {"arrows": "to", "color": "#34495E", "from": "FeatureAbstraction", "label": "subClassOf", "to": "LearningObjective"}, {"arrows": "to", "color": "#34495E", "from": "SandboxedExecutionEnvironment", "label": "subClassOf", "to": "ExecutionEnvironment"}, {"arrows": "to", "color": "#34495E", "from": "BiasVarianceTradeOff", "label": "subClassOf", "to": "OptimizationCriterion"}, {"arrows": "to", "color": "#34495E", "from": "InfluenceOnRewardVariance", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "Demonstration", "label": "subClassOf", "to": "CorrelationDemonstration"}, {"arrows": "to", "color": "#34495E", "from": "VEOrder", "label": "subClassOf", "to": "LearningOrder"}, {"arrows": "to", "color": "#34495E", "from": "ExampleBasedControl", "label": "subClassOf", "to": "ControlIntegration"}, {"arrows": "to", "color": "#34495E", "from": "NonlinearFunctionApproximation", "label": "subClassOf", "to": "FunctionApproximation"}, {"arrows": "to", "color": "#34495E", "from": "LongTermCreditAssignment", "label": "subClassOf", "to": "CreditAssignment"}, {"arrows": "to", "color": "#34495E", "from": "OptimalRewardRedistribution", "label": "subClassOf", "to": "RewardRedistribution"}, {"arrows": "to", "color": "#34495E", "from": "StaticRewardMitigation", "label": "subClassOf", "to": "SpuriousRewardMitigationStrategy"}, {"arrows": "to", "color": "#34495E", "from": "LatentStateRepresentation", "label": "subClassOf", "to": "Representation"}, {"arrows": "to", "color": "#34495E", "from": "ResidualBiasCorrectionTechnique", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "HierarchicalReinforcementLearning", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "LSTMNetwork", "label": "subClassOf", "to": "NetworkStructure"}, {"arrows": "to", "color": "#34495E", "from": "DownstreamReinforcementLearning", "label": "subClassOf", "to": "ReinforcementLearning"}, {"arrows": "to", "color": "#34495E", "from": "PolicyComparison", "label": "subClassOf", "to": "Policy"}, {"arrows": "to", "color": "#34495E", "from": "RewardPredictiveAssociation", "label": "subClassOf", "to": "Association"}, {"arrows": "to", "color": "#34495E", "from": "ValuePolytope", "label": "subClassOf", "to": "GeometricProperty"}, {"arrows": "to", "color": "#34495E", "from": "ActionRepeatConfiguration", "label": "subClassOf", "to": "Policy"}, {"arrows": "to", "color": "#34495E", "from": "RecursiveClassificationApproach", "label": "subClassOf", "to": "ClassificationApproach"}, {"arrows": "to", "color": "#34495E", "from": "GRUArchitecture", "label": "subClassOf", "to": "NeuralNetwork"}, {"arrows": "to", "color": "#34495E", "from": "PerformanceMetric", "label": "subClassOf", "to": "LearningObjective"}, {"arrows": "to", "color": "#34495E", "from": "UnsupervisedVisualRepresentation", "label": "subClassOf", "to": "VisualRepresentation"}, {"arrows": "to", "color": "#34495E", "from": "TemporalResolution", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "AcademicWorkshop", "label": "subClassOf", "to": "Workshop"}, {"arrows": "to", "color": "#34495E", "from": "EnhancedPredictionProbingPerformance", "label": "subClassOf", "to": "PredictionProbingPerformance"}, {"arrows": "to", "color": "#34495E", "from": "MultiTaskLearning", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "DivergenceBasedRegularization", "label": "subClassOf", "to": "RegularizationTechnique"}, {"arrows": "to", "color": "#34495E", "from": "ModelFidelity", "label": "subClassOf", "to": "QualityMetric"}, {"arrows": "to", "color": "#34495E", "from": "QValue", "label": "subClassOf", "to": "Estimation"}, {"arrows": "to", "color": "#34495E", "from": "LearningStability", "label": "subClassOf", "to": "LearningDynamic"}, {"arrows": "to", "color": "#34495E", "from": "Policy", "label": "subClassOf", "to": "LearningObjective"}, {"arrows": "to", "color": "#34495E", "from": "FeedforwardNetwork", "label": "subClassOf", "to": "NetworkStructure"}, {"arrows": "to", "color": "#34495E", "from": "FiniteStateMachineMemory", "label": "subClassOf", "to": "Memory"}, {"arrows": "to", "color": "#34495E", "from": "StateTransitionDynamics", "label": "subClassOf", "to": "RewardFunction"}, {"arrows": "to", "color": "#34495E", "from": "DenseSurrogateRewardFunction", "label": "subClassOf", "to": "Reward"}, {"arrows": "to", "color": "#34495E", "from": "RewardManagement", "label": "subClassOf", "to": "ReinforcementLearning"}, {"arrows": "to", "color": "#34495E", "from": "TransitionFunction", "label": "subClassOf", "to": "Function"}, {"arrows": "to", "color": "#34495E", "from": "AIResearch", "label": "subClassOf", "to": "ResearchField"}, {"arrows": "to", "color": "#34495E", "from": "RewardSignal", "label": "subClassOf", "to": "Reward"}, {"arrows": "to", "color": "#34495E", "from": "EnergyDistance", "label": "subClassOf", "to": "DistanceMetric"}, {"arrows": "to", "color": "#34495E", "from": "RecurrentNeuralNetwork", "label": "subClassOf", "to": "NeuralNetwork"}, {"arrows": "to", "color": "#34495E", "from": "AdaptiveRewardMitigation", "label": "subClassOf", "to": "SpuriousRewardMitigationStrategy"}, {"arrows": "to", "color": "#34495E", "from": "MemoryUtilizationStrategy", "label": "subClassOf", "to": "MemoryPreservationStrategy"}, {"arrows": "to", "color": "#34495E", "from": "ModelCapacity", "label": "subClassOf", "to": "Capacity"}, {"arrows": "to", "color": "#34495E", "from": "TemporalCreditAssignment", "label": "subClassOf", "to": "Reward"}, {"arrows": "to", "color": "#34495E", "from": "IterativeControlMethod", "label": "subClassOf", "to": "ControlMethod"}, {"arrows": "to", "color": "#34495E", "from": "ExampleBasedLearning", "label": "subClassOf", "to": "DirectLearning"}, {"arrows": "to", "color": "#34495E", "from": "PlanningPerformanceDifference", "label": "subClassOf", "to": "PerformanceComparison"}, {"arrows": "to", "color": "#34495E", "from": "ScalableReinforcementLearning", "label": "subClassOf", "to": "EnergyOptimization"}, {"arrows": "to", "color": "#34495E", "from": "DynamicGameEnvironment", "label": "subClassOf", "to": "GameEnvironment"}, {"arrows": "to", "color": "#34495E", "from": "SubManager", "label": "subClassOf", "to": "Manager"}, {"arrows": "to", "color": "#34495E", "from": "MemoryPerformance", "label": "subClassOf", "to": "PerformanceMetric"}, {"arrows": "to", "color": "#34495E", "from": "HierarchicalReinforcementLearningArchitecture", "label": "subClassOf", "to": "HierarchicalReinforcementLearning"}, {"arrows": "to", "color": "#34495E", "from": "FalseRingMDP", "label": "subClassOf", "to": "MarkovDecisionProcess"}, {"arrows": "to", "color": "#34495E", "from": "LongHorizonImitationLearning", "label": "subClassOf", "to": "ImitationLearning"}, {"arrows": "to", "color": "#34495E", "from": "ActionExecution", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "RecurrentNetwork", "label": "subClassOf", "to": "NetworkStructure"}, {"arrows": "to", "color": "#34495E", "from": "DelayedCreditAssignment", "label": "subClassOf", "to": "CreditAssignment"}, {"arrows": "to", "color": "#34495E", "from": "TemporalAttentionMechanism", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "HistoryCompressionFunction", "label": "subClassOf", "to": "Function"}, {"arrows": "to", "color": "#34495E", "from": "DomainAgnosticBenchmark", "label": "subClassOf", "to": "Benchmark"}, {"arrows": "to", "color": "#34495E", "from": "ModernControlMethod", "label": "subClassOf", "to": "ControlMethod"}, {"arrows": "to", "color": "#34495E", "from": "AgentTemporalAttentionMechanism", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "DecentralizedAgentPolicy", "label": "subClassOf", "to": "Policy"}, {"arrows": "to", "color": "#34495E", "from": "TaskDelegation", "label": "subClassOf", "to": "LearningObjective"}, {"arrows": "to", "color": "#34495E", "from": "OptimalPolicySelection", "label": "subClassOf", "to": "PolicySelection"}, {"arrows": "to", "color": "#34495E", "from": "EpisodicRewardDecomposition", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "TemporalAttentionPattern", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "FacilityUsage", "label": "subClassOf", "to": "ResourceAllocation"}, {"arrows": "to", "color": "#34495E", "from": "DomainSpecificBenchmark", "label": "subClassOf", "to": "Benchmark"}, {"arrows": "to", "color": "#34495E", "from": "HierarchicalLearningArchitecture", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "SelfSupervisedLearning", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "Reward", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "RewardManagement", "label": "subClassOf", "to": "Reward"}, {"arrows": "to", "color": "#34495E", "from": "TaskDelegation", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "PolicyGradientMethod", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "RecurrentNeuralNetwork", "label": "subClassOf", "to": "NetworkStructure"}, {"arrows": "to", "color": "#34495E", "from": "RecurrentNeuralNetwork", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "IndirectLearning", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "MarkovDecisionProcess", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "EnergyOptimization", "label": "subClassOf", "to": "ReinforcementLearning"}, {"arrows": "to", "color": "#34495E", "from": "ExampleBasedLearning", "label": "subClassOf", "to": "ClassifierBasedLearning"}, {"arrows": "to", "color": "#34495E", "from": "SelectionStrategy", "label": "subClassOf", "to": "LearningAlgorithm"}, {"arrows": "to", "color": "#34495E", "from": "ExampleBasedControl", "label": "subClassOf", "to": "ModernControlMethod"}, {"arrows": "to", "color": "#34495E", "from": "ModernControlMethod", "label": "subClassOf", "to": "LearningAlgorithm"}, {"arrows": "to", "color": "#34495E", "from": "NonlinearFunctionApproximation", "label": "subClassOf", "to": "ApproximatorFunction"}, {"arrows": "to", "color": "#34495E", "from": "RewardRedistribution", "label": "subClassOf", "to": "Reward"}, {"arrows": "to", "color": "#34495E", "from": "WassersteinDistance", "label": "subClassOf", "to": "Function"}, {"arrows": "to", "color": "#34495E", "from": "ReinforcementLearning", "label": "subClassOf", "to": "AIResearch"}, {"arrows": "to", "color": "#34495E", "from": "Community", "label": "subClassOf", "to": "AIResearch"}, {"arrows": "to", "color": "#34495E", "from": "AdaptiveRewardMitigation", "label": "subClassOf", "to": "Reward"}, {"arrows": "to", "color": "#34495E", "from": "OptimalPolicySelection", "label": "subClassOf", "to": "Policy"}, {"arrows": "to", "color": "#34495E", "from": "RewardPredictiveAssociation", "label": "subClassOf", "to": "Reward"}, {"arrows": "to", "color": "#34495E", "from": "DomainAgnosticBenchmark", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "LongHorizonImitationLearning", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "ConfidenceInterval", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "PerformanceMetric", "label": "subClassOf", "to": "QualityMetric"}, {"arrows": "to", "color": "#34495E", "from": "Capacity", "label": "subClassOf", "to": "QualityMetric"}, {"arrows": "to", "color": "#34495E", "from": "EnhancedPredictionProbingPerformance", "label": "subClassOf", "to": "PerformanceMetric"}, {"arrows": "to", "color": "#34495E", "from": "DynamicGameEnvironment", "label": "subClassOf", "to": "DiverseEnvironment"}, {"arrows": "to", "color": "#34495E", "from": "QValue", "label": "subClassOf", "to": "Reward"}, {"arrows": "to", "color": "#34495E", "from": "Demonstration", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "FacilityUsage", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "FiniteStateMachineMemory", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "Manager", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "StateTransitionDynamics", "label": "subClassOf", "to": "StateTransition"}, {"arrows": "to", "color": "#34495E", "from": "StochasticDecisionProcess", "label": "subClassOf", "to": "MarkovDecisionProcess"}, {"arrows": "to", "color": "#34495E", "from": "MemoryUtilizationStrategy", "label": "subClassOf", "to": "Memory"}, {"arrows": "to", "color": "#34495E", "from": "LearningOrder", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "ValuePolytope", "label": "subClassOf", "to": "QualityMetric"}, {"arrows": "to", "color": "#34495E", "from": "PlanningPerformanceDifference", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "DivergenceBasedRegularization", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "RecursiveClassificationApproach", "label": "subClassOf", "to": "ClassifierBasedLearning"}, {"arrows": "to", "color": "#34495E", "from": "AcademicWorkshop", "label": "subClassOf", "to": "AIResearch"}, {"arrows": "to", "color": "#34495E", "from": "LearningDynamic", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "UnsupervisedVisualRepresentation", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "BiasVarianceTradeOff", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "ExecutionEnvironment", "label": "subClassOf", "to": "LearningProcess"}, {"arrows": "to", "color": "#34495E", "from": "LatentStateRepresentation", "label": "subClassOf", "to": "FeatureAbstraction"}, {"arrows": "to", "color": "#45B7D1", "from": "EnergyOptimization", "label": "EnergyConsumptionAnalysis", "to": "PerformanceMetric"}, {"arrows": "to", "color": "#45B7D1", "from": "RecurrentNeuralNetwork", "label": "ExtendedMemoryEffect", "to": "MemoryPerformance"}, {"arrows": "to", "color": "#45B7D1", "from": "ReinforcementLearning", "label": "FiniteStateMachineMemory", "to": "Memory"}, {"arrows": "to", "color": "#45B7D1", "from": "ReinforcementLearning", "label": "RewardManagement", "to": "Reward"}, {"arrows": "to", "color": "#45B7D1", "from": "RecurrentNeuralNetwork", "label": "LatentVariableIntroduction", "to": "ReinforcementLearning"}, {"arrows": "to", "color": "#45B7D1", "from": "ReinforcementLearning", "label": "NeuralNetworkModelSelection", "to": "NeuralNetwork"}, {"arrows": "to", "color": "#45B7D1", "from": "MultiTaskLearning", "label": "TaskSpecification", "to": "LearningObjective"}, {"arrows": "to", "color": "#45B7D1", "from": "ReinforcementLearning", "label": "SparseFeedbackChallenge", "to": "LearningObjective"}, {"arrows": "to", "color": "#45B7D1", "from": "ReinforcementLearning", "label": "RewardFunctionOptimization", "to": "LearningProcess"}, {"arrows": "to", "color": "#45B7D1", "from": "DenseSurrogateRewardFunction", "label": "TemporalCreditAssignment", "to": "LearningProcess"}, {"arrows": "to", "color": "#45B7D1", "from": "ReinforcementLearning", "label": "ImpactAnalysis", "to": "PerformanceMetric"}, {"arrows": "to", "color": "#45B7D1", "from": "DiverseEnvironment", "label": "RewardProbingTechnique", "to": "Reward"}, {"arrows": "to", "color": "#45B7D1", "from": "RecursiveClassificationApproach", "label": "OptimalityGuaranteeAnalysis", "to": "Reward"}, {"arrows": "to", "color": "#45B7D1", "from": "LearningObjective", "label": "RewardShaping", "to": "Reward"}, {"arrows": "to", "color": "#45B7D1", "from": "HierarchicalReinforcementLearningArchitecture", "label": "StateDecompositionMethod", "to": "StateTransition"}, {"arrows": "to", "color": "#45B7D1", "from": "ReinforcementLearning", "label": "VisualRepresentationEvaluation", "to": "VisualRepresentation"}, {"arrows": "to", "color": "#45B7D1", "from": "DecentralizedAgentPolicy", "label": "DecentralizedPolicyPerformance", "to": "PerformanceMetric"}, {"arrows": "to", "color": "#45B7D1", "from": "LearningProcess", "label": "HierarchicalLearningArchitecture", "to": "Policy"}, {"arrows": "to", "color": "#45B7D1", "from": "HierarchicalReinforcementLearning", "label": "BufferStateRepresentation", "to": "CreditAssignment"}, {"arrows": "to", "color": "#45B7D1", "from": "ReinforcementLearning", "label": "PolicyImprovement", "to": "Policy"}, {"arrows": "to", "color": "#45B7D1", "from": "LearningProcess", "label": "IntrinsicRewardUtilization", "to": "LatentStateRepresentation"}, {"arrows": "to", "color": "#45B7D1", "from": "TemporalCreditAssignment", "label": "EpisodicRewardRedistribution", "to": "LearningProcess"}, {"arrows": "to", "color": "#45B7D1", "from": "RewardPredictiveAssociation", "label": "SyntheticReturnGeneration", "to": "LongTermCreditAssignment"}, {"arrows": "to", "color": "#45B7D1", "from": "RecurrentNeuralNetwork", "label": "MemoryPreservationStrategy", "to": "Memory"}, {"arrows": "to", "color": "#45B7D1", "from": "RewardRedistribution", "label": "RewardRedistributionAdaptation", "to": "LearningProcess"}, {"arrows": "to", "color": "#45B7D1", "from": "ReinforcementLearning", "label": "ReinforcementLearningAlgorithm", "to": "IterativeControlMethod"}, {"arrows": "to", "color": "#45B7D1", "from": "Policy", "label": "RewardRedistributionStrategy", "to": "RewardRedistribution"}, {"arrows": "to", "color": "#45B7D1", "from": "AgentTemporalAttentionMechanism", "label": "TemporalAttentionMechanismEnhancement", "to": "PerformanceMetric"}, {"arrows": "to", "color": "#45B7D1", "from": "ReinforcementLearning", "label": "IncreasingModelOrder", "to": "VEOrder"}, {"arrows": "to", "color": "#45B7D1", "from": "MarkovDecisionProcess", "label": "KStepBellmanOperator", "to": "Reward"}, {"arrows": "to", "color": "#45B7D1", "from": "SubManager", "label": "LearningDynamics", "to": "LearningDynamic"}, {"arrows": "to", "color": "#45B7D1", "from": "DecentralizedAgentPolicy", "label": "MultiAgentLearning", "to": "LearningProcess"}, {"arrows": "to", "color": "#45B7D1", "from": "Manager", "label": "LearningDynamics", "to": "LearningDynamic"}, {"arrows": "to", "color": "#45B7D1", "from": "LearningProcess", "label": "MemoryUtilizationStrategy", "to": "Memory"}, {"arrows": "to", "color": "#45B7D1", "from": "ImitationLearning", "label": "StateTransitionDynamics", "to": "RewardFunction"}, {"arrows": "to", "color": "#45B7D1", "from": "Reward", "label": "SecondOrderMarkovRewardRedistribution", "to": "ReturnEquivalentSDP"}, {"arrows": "to", "color": "#45B7D1", "from": "ActionRepeatConfiguration", "label": "TransitionPolicy", "to": "LearningProcess"}, {"arrows": "to", "color": "#45B7D1", "from": "HierarchicalReinforcementLearning", "label": "StateInformationFlow", "to": "TaskDelegation"}, {"arrows": "to", "color": "#45B7D1", "from": "EpisodicRewardDecomposition", "label": "RewardPredictionStrategy", "to": "Reward"}, {"arrows": "to", "color": "#45B7D1", "from": "StateTransition", "label": "PartiallyObservableEnvironment", "to": "ReinforcementLearning"}, {"arrows": "to", "color": "#45B7D1", "from": "HierarchicalReinforcementLearning", "label": "LongTermMemoryPreservation", "to": "Memory"}, {"arrows": "to", "color": "#45B7D1", "from": "TemporalResolution", "label": "ImpactOnLearning", "to": "LearningDynamic"}, {"arrows": "to", "color": "#45B7D1", "from": "HierarchicalReinforcementLearning", "label": "HierarchicalLearningArchitecture", "to": "LearningObjective"}, {"arrows": "to", "color": "#45B7D1", "from": "DecentralizedAgentPolicy", "label": "MultiAgentSystemLearning", "to": "DelayedEpisodicReward"}, {"arrows": "to", "color": "#45B7D1", "from": "ReinforcementLearning", "label": "AdversarialTraining", "to": "PolicyGradientMethod"}, {"arrows": "to", "color": "#45B7D1", "from": "ReinforcementLearning", "label": "StateTransition", "to": "LatentStateRepresentation"}, {"arrows": "to", "color": "#45B7D1", "from": "HierarchicalReinforcementLearning", "label": "NonMarkovianDynamics", "to": "ReinforcementLearning"}, {"arrows": "to", "color": "#45B7D1", "from": "RecurrentNeuralNetwork", "label": "RewardPrediction", "to": "Reward"}, {"arrows": "to", "color": "#45B7D1", "from": "Reward", "label": "ReturnDecomposition", "to": "CreditAssignment"}, {"arrows": "to", "color": "#45B7D1", "from": "ResourceAllocation", "label": "OptimizationStrategy", "to": "LearningProcess"}, {"arrows": "to", "color": "#45B7D1", "from": "SandboxedExecutionEnvironment", "label": "InformationLeakPreventionStrategy", "to": "LearningProcess"}, {"arrows": "to", "color": "#45B7D1", "from": "SubManager", "label": "RewardHidingStrategy", "to": "Reward"}, {"arrows": "to", "color": "#45B7D1", "from": "Reward", "label": "DemonstrationBasedIntrinsicRewardReshaping", "to": "PolicyGradientMethod"}, {"arrows": "to", "color": "#9B59B6", "from": "StateTransition", "label": "TransitionQuality", "to": "datatype: xsd:float"}, {"arrows": "to", "color": "#9B59B6", "from": "HistoryCompressionFunction", "label": "ApproximationError", "to": "datatype: xsd:float"}, {"arrows": "to", "color": "#9B59B6", "from": "ReinforcementLearning", "label": "FutureSuccessProbability", "to": "datatype: xsd:float"}, {"arrows": "to", "color": "#9B59B6", "from": "ReinforcementLearning", "label": "LossFunction", "to": "datatype: xsd:string"}, {"arrows": "to", "color": "#9B59B6", "from": "AgentTemporalAttentionMechanism", "label": "AttentionDepth", "to": "datatype: xsd:float"}, {"arrows": "to", "color": "#9B59B6", "from": "GRUArchitecture", "label": "OptimizationStrategy", "to": "datatype: xsd:string"}, {"arrows": "to", "color": "#9B59B6", "from": "EpisodicRewardDecomposition", "label": "Interpretability", "to": "datatype: xsd:string"}, {"arrows": "to", "color": "#9B59B6", "from": "Function", "label": "LipschitzConstant", "to": "datatype: xsd:float"}, {"arrows": "to", "color": "#9B59B6", "from": "ControlIntegration", "label": "Performance", "to": "datatype: xsd:string"}, {"arrows": "to", "color": "#9B59B6", "from": "SandboxedExecutionEnvironment", "label": "Evaluation", "to": "datatype: xsd:string"}, {"arrows": "to", "color": "#9B59B6", "from": "ResidualBiasCorrectionTechnique", "label": "PolicyGradientEstimation", "to": "datatype: xsd:string"}, {"arrows": "to", "color": "#9B59B6", "from": "SpuriousRewardMitigationStrategy", "label": "MitigationEffectiveness", "to": "datatype: xsd:float"}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {
    "configure": {
        "enabled": false
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "forceAtlas2Based": {
            "avoidOverlap": 0,
            "centralGravity": 0.01,
            "damping": 0.4,
            "gravitationalConstant": -50,
            "springConstant": 0.08,
            "springLength": 100
        },
        "solver": "forceAtlas2Based",
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  
                      network.on("stabilizationProgress", function(params) {
                          document.getElementById('loadingBar').removeAttribute("style");
                          var maxWidth = 496;
                          var minWidth = 20;
                          var widthFactor = params.iterations/params.total;
                          var width = Math.max(minWidth,maxWidth * widthFactor);
                          document.getElementById('bar').style.width = width + 'px';
                          document.getElementById('text').innerHTML = Math.round(widthFactor*100) + '%';
                      });
                      network.once("stabilizationIterationsDone", function() {
                          document.getElementById('text').innerHTML = '100%';
                          document.getElementById('bar').style.width = '496px';
                          document.getElementById('loadingBar').style.opacity = 0;
                          // really clean the dom element
                          setTimeout(function () {document.getElementById('loadingBar').style.display = 'none';}, 500);
                      });
                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>